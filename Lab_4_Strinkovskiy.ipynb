{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8900,"databundleVersionId":862232,"sourceType":"competition"},{"sourceId":8167622,"sourceType":"datasetVersion","datasetId":4833281},{"sourceId":8183150,"sourceType":"datasetVersion","datasetId":4845118}],"dockerImageVersionId":30702,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport math\nimport os\nimport cv2\nimport IPython.display as ipd \nimport librosa \nimport librosa.display\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\nimport torchvision\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T09:51:10.370272Z","iopub.execute_input":"2024-04-21T09:51:10.370699Z","iopub.status.idle":"2024-04-21T09:51:10.378846Z","shell.execute_reply.started":"2024-04-21T09:51:10.370666Z","shell.execute_reply":"2024-04-21T09:51:10.377671Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:11.900950Z","iopub.execute_input":"2024-04-21T09:51:11.901369Z","iopub.status.idle":"2024-04-21T09:51:11.907484Z","shell.execute_reply.started":"2024-04-21T09:51:11.901335Z","shell.execute_reply":"2024-04-21T09:51:11.906096Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"trainPath = '/kaggle/input/freesound-audio-tagging/audio_train/'\ntrainData = pd.read_csv('/kaggle/input/freesound-audio-tagging/train.csv')\ntrainData.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:14.692451Z","iopub.execute_input":"2024-04-21T09:51:14.693815Z","iopub.status.idle":"2024-04-21T09:51:14.716970Z","shell.execute_reply.started":"2024-04-21T09:51:14.693776Z","shell.execute_reply":"2024-04-21T09:51:14.715921Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"          fname         label  manually_verified\n0  00044347.wav        Hi-hat                  0\n1  001ca53d.wav     Saxophone                  1\n2  002d256b.wav       Trumpet                  0\n3  0033e230.wav  Glockenspiel                  1\n4  00353774.wav         Cello                  1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>label</th>\n      <th>manually_verified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00044347.wav</td>\n      <td>Hi-hat</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001ca53d.wav</td>\n      <td>Saxophone</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>002d256b.wav</td>\n      <td>Trumpet</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0033e230.wav</td>\n      <td>Glockenspiel</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00353774.wav</td>\n      <td>Cello</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataLabels = np.unique(trainData.label.values)\ndataLabelsEncoder = {dataLabel:i for i, dataLabel in enumerate(dataLabels)}","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:15.990621Z","iopub.execute_input":"2024-04-21T09:51:15.991524Z","iopub.status.idle":"2024-04-21T09:51:16.006284Z","shell.execute_reply.started":"2024-04-21T09:51:15.991487Z","shell.execute_reply":"2024-04-21T09:51:16.005128Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, dataframe, test=False):\n        self.dataframe = dataframe\n        self.test = test\n\n    def __getitem__(self, index):\n        path_to_file = self.get_path_to_file(index)\n        signal = self.preprocess_signal(path_to_file)\n\n        x = np.stack([cv2.resize(signal, (128, 128)) for _ in range(3)])\n\n        if self.test == False:\n            y = dataLabelsEncoder[self.dataframe.label.values[index]]\n            return torch.tensor(x, dtype=torch.float), y\n        else:\n             return torch.tensor(x, dtype=torch.float)\n\n    def get_path_to_file(self, index):\n        if self.test:\n            return '../input/freesound-audio-tagging/audio_test/' + self.dataframe.fname.values[index]\n        else:\n            return '../input/freesound-audio-tagging/audio_train/' + self.dataframe.fname.values[index]\n\n    def preprocess_signal(self, path_to_file):\n        signal, _ = librosa.load(path_to_file)\n        signal = librosa.feature.melspectrogram(y=signal)\n        return librosa.power_to_db(signal, ref=np.max)\n\n    def __len__(self):\n        return self.dataframe.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:17.646338Z","iopub.execute_input":"2024-04-21T09:51:17.646725Z","iopub.status.idle":"2024-04-21T09:51:17.659107Z","shell.execute_reply.started":"2024-04-21T09:51:17.646696Z","shell.execute_reply":"2024-04-21T09:51:17.657850Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\n\nxTrain, xVal, yTrain, yVal = train_test_split(trainData, trainData, test_size=0.2, shuffle=True, random_state=5)\n\ntrainSet = Dataset(xTrain)\nvalSet = Dataset(xVal)\ntrainLoader = DataLoader(trainSet, batch_size=batch_size, shuffle=True)\nvalLoader = DataLoader(valSet , batch_size=batch_size, shuffle=True)\n\nprint('Training set: {}, Validation set: {}'.format(xTrain.shape[0], xVal.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:19.063541Z","iopub.execute_input":"2024-04-21T09:51:19.063957Z","iopub.status.idle":"2024-04-21T09:51:19.079754Z","shell.execute_reply.started":"2024-04-21T09:51:19.063926Z","shell.execute_reply":"2024-04-21T09:51:19.077366Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Training set: 7578, Validation set: 1895\n","output_type":"stream"}]},{"cell_type":"code","source":"# Путь к локально сохраненным весам модели\nlocal_weights_path = \"/kaggle/input/hahahah/efficientnet_b0_rwightman-7f5810bc.pth\"","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:20.321458Z","iopub.execute_input":"2024-04-21T09:51:20.321895Z","iopub.status.idle":"2024-04-21T09:51:20.328089Z","shell.execute_reply.started":"2024-04-21T09:51:20.321862Z","shell.execute_reply":"2024-04-21T09:51:20.326701Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Загрузка модели без предварительного обучения\nmodel = torchvision.models.efficientnet_b0(pretrained=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:21.547061Z","iopub.execute_input":"2024-04-21T09:51:21.547473Z","iopub.status.idle":"2024-04-21T09:51:21.685431Z","shell.execute_reply.started":"2024-04-21T09:51:21.547429Z","shell.execute_reply":"2024-04-21T09:51:21.684277Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Загрузка локально сохраненных весов\nstate_dict = torch.load(local_weights_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:22.663464Z","iopub.execute_input":"2024-04-21T09:51:22.663877Z","iopub.status.idle":"2024-04-21T09:51:23.004552Z","shell.execute_reply.started":"2024-04-21T09:51:22.663846Z","shell.execute_reply":"2024-04-21T09:51:23.003393Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Загрузка весов в модель\nmodel.load_state_dict(state_dict)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:26.798345Z","iopub.execute_input":"2024-04-21T09:51:26.798779Z","iopub.status.idle":"2024-04-21T09:51:26.827881Z","shell.execute_reply.started":"2024-04-21T09:51:26.798745Z","shell.execute_reply":"2024-04-21T09:51:26.826824Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# Изменение последнего слоя модели\nmodel.classifier[1] = torch.nn.Linear(1280, 41)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:28.337960Z","iopub.execute_input":"2024-04-21T09:51:28.338961Z","iopub.status.idle":"2024-04-21T09:51:28.344838Z","shell.execute_reply.started":"2024-04-21T09:51:28.338924Z","shell.execute_reply":"2024-04-21T09:51:28.343469Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Перенос модели на устройство\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:32.488889Z","iopub.execute_input":"2024-04-21T09:51:32.489620Z","iopub.status.idle":"2024-04-21T09:51:32.512352Z","shell.execute_reply.started":"2024-04-21T09:51:32.489565Z","shell.execute_reply":"2024-04-21T09:51:32.511350Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n      )\n    )\n    (2): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n      )\n    )\n    (3): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n      )\n    )\n    (4): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n      )\n    )\n    (5): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n      )\n    )\n    (6): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n      )\n    )\n    (7): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n      )\n    )\n    (8): Conv2dNormActivation(\n      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Dropout(p=0.2, inplace=True)\n    (1): Linear(in_features=1280, out_features=41, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from time import time \nstart_time = time()\n\nepochs = 1\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncost = torch.nn.CrossEntropyLoss()\ntotal_batches = len(trainLoader)\nfor epoch in range(epochs):\n    train_loss = 0\n    val_loss = 0\n    train_correct = 0\n    val_correct = 0\n    model.train()\n    for batch_idx, (x, y) in enumerate(trainLoader):\n        optimizer.zero_grad()\n        x, y = x.to(device), y.to(device)\n        pred = model(x)\n        loss = cost(pred, y)\n        train_loss += cost(pred, y).item()\n        train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n        loss.backward()\n        optimizer.step()\n        # Выводим процент выполнения эпохи\n        percent_complete = ((batch_idx + 1) / total_batches) * 100\n        print(f\"\\rEpoch {epoch + 1}/{epochs} [{int(percent_complete)}%]\", end='')\n\n    model.eval()\n    with torch.no_grad():\n        for x, y in valLoader:\n            x, y = x.to(device), y.to(device)\n            pred = model(x)\n            loss = cost(pred, y)\n            val_loss += cost(pred, y).item()\n            val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    train_loss = train_loss / len(trainLoader)\n    val_loss = val_loss / len(valLoader)\n    train_accuracy = train_correct / len(xTrain)\n    val_accuracy = val_correct / len(xVal)\n    print()\n    print(\"epoch = %d, train_loss = %.5f, val_loss = %.5f, train_accuracy = %.5f, val_accuracy = %.5f\" % (epoch, train_loss, val_loss, train_accuracy, val_accuracy))\n    \nend_time = time()\ntotal_time = end_time - start_time\nprint(f'Total Training Time: {total_time:.2f} seconds')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T09:51:43.380767Z","iopub.execute_input":"2024-04-21T09:51:43.381166Z","iopub.status.idle":"2024-04-21T10:10:25.507081Z","shell.execute_reply.started":"2024-04-21T09:51:43.381134Z","shell.execute_reply":"2024-04-21T10:10:25.505570Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch 1/1 [100%]\nepoch = 0, train_loss = 1.79080, val_loss = 1.19262, train_accuracy = 0.51491, val_accuracy = 0.66596\nTotal Training Time: 1122.11 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"test = pd.read_csv('../input/freesound-audio-tagging/sample_submission.csv')\n\ntest_dataset = Dataset(test, test=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\npredictions = torch.tensor([])\nmodel.eval()\nfor x in test_loader:\n    x = x.to(device)\n    with torch.no_grad():\n        y_hat = model(x)\n    predictions = torch.cat([predictions, y_hat.cpu()])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T10:23:22.543290Z","iopub.execute_input":"2024-04-21T10:23:22.543768Z","iopub.status.idle":"2024-04-21T10:31:37.083067Z","shell.execute_reply.started":"2024-04-21T10:23:22.543718Z","shell.execute_reply":"2024-04-21T10:31:37.081941Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=0\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-04-21T10:42:54.290887Z","iopub.execute_input":"2024-04-21T10:42:54.291336Z","iopub.status.idle":"2024-04-21T10:42:54.297159Z","shell.execute_reply.started":"2024-04-21T10:42:54.291302Z","shell.execute_reply":"2024-04-21T10:42:54.296089Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Преобразуйте массив NumPy обратно в тензор PyTorch\npredictions_tensor = torch.from_numpy(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T10:42:56.795526Z","iopub.execute_input":"2024-04-21T10:42:56.796309Z","iopub.status.idle":"2024-04-21T10:42:56.801681Z","shell.execute_reply.started":"2024-04-21T10:42:56.796271Z","shell.execute_reply":"2024-04-21T10:42:56.800276Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Примените softmax к тензору\npredictions_softmax = torch.nn.functional.softmax(predictions_tensor, dim=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T10:42:58.070530Z","iopub.execute_input":"2024-04-21T10:42:58.070998Z","iopub.status.idle":"2024-04-21T10:42:58.077407Z","shell.execute_reply.started":"2024-04-21T10:42:58.070966Z","shell.execute_reply":"2024-04-21T10:42:58.076151Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Преобразуйте результат обратно в массив NumPy, если это необходимо\npredictions_softmax_numpy = predictions_softmax.detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T10:42:59.400848Z","iopub.execute_input":"2024-04-21T10:42:59.401276Z","iopub.status.idle":"2024-04-21T10:42:59.406658Z","shell.execute_reply.started":"2024-04-21T10:42:59.401242Z","shell.execute_reply":"2024-04-21T10:42:59.405340Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_top1 = test.copy()\n\nN = len(test)\nfor i in range(N):\n    p = predictions[i, :]\n    idx = np.argmax(p)\n    submission_top1.label[i] = dataLabels[idx]\n\nsubmission_top1.to_csv('submission_final.csv', index=False, header=True)\n\nsubmission_top1.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T10:48:48.399479Z","iopub.execute_input":"2024-04-21T10:48:48.399894Z","iopub.status.idle":"2024-04-21T10:48:49.830142Z","shell.execute_reply.started":"2024-04-21T10:48:48.399864Z","shell.execute_reply":"2024-04-21T10:48:49.828973Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/788823920.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  submission_top1.label[i] = dataLabels[idx]\n","output_type":"stream"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"          fname      label\n0  00063640.wav    Shatter\n1  0013a1db.wav      Flute\n2  002bb878.wav  Bass_drum\n3  002d392d.wav  Bass_drum\n4  00326aa9.wav       Oboe","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00063640.wav</td>\n      <td>Shatter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0013a1db.wav</td>\n      <td>Flute</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>002bb878.wav</td>\n      <td>Bass_drum</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>002d392d.wav</td>\n      <td>Bass_drum</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00326aa9.wav</td>\n      <td>Oboe</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}